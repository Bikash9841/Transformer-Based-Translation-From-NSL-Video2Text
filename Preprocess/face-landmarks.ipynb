{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Media-Pipe Preprocessing"]},{"cell_type":"markdown","metadata":{},"source":["## Convert Multiple Raw Videos into Mediapipe Stick-Figures"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","import cv2\n","import mediapipe as mp\n","import numpy as np\n","import time\n","import os\n","import glob\n","\n","parent_directory='ndata'\n","# video_dir='म घर मा धेरै काम गर्छु ।/'\n","\n","\n","mp_drawing = mp.solutions.drawing_utils\n","mp_drawing_styles = mp.solutions.drawing_styles\n","mp_pose = mp.solutions.pose\n","mp_hands = mp.solutions.hands\n","\n","\n","prev_frame_time=0\n","new_frame_time=0\n","\n","# For webcam input:\n","# cap = cv2.VideoCapture(0)\n","for video_dirs in glob.glob(parent_directory+'/*'):\n","\n","  video_dir=video_dirs.removeprefix(parent_directory+'/')\n","\n","  for f in range(2):\n","    for video in glob.glob(video_dirs+'/*'):\n","\n","      cap=cv2.VideoCapture(video)\n","\n","      fourcc = cv2.VideoWriter_fourcc('X','V','I','D')\n","\n","      # for horizontal flip augmentation\n","      if f==0:\n","        save_video_path=os.path.join('nprocessed_data/',video_dir,video.removeprefix(video_dirs+'/'))\n","      elif f==1:\n","        save_video_path=os.path.join('nprocessed_data/',video_dir,'f_'+video.removeprefix(video_dirs+'/'))\n","\n","      videoWriter = cv2.VideoWriter(save_video_path, fourcc, 30.0, (224,224))\n","\n","      with mp_pose.Pose(\n","          min_detection_confidence=0.5,\n","          min_tracking_confidence=0.5) as pose:\n","        with mp_hands.Hands(\n","            min_detection_confidence=0.5,\n","            min_tracking_confidence=0.5) as hands:\n","          while cap.isOpened():\n","            success, image = cap.read()\n","            if not success:\n","              print(\"Ignoring empty camera frame.\")\n","              break\n","              # If loading a video, use 'break' instead of 'continue'.\n","              # continue\n","\n","            image=cv2.resize(image,(224,224),interpolation=cv2.INTER_AREA)\n","\n","            # To improve performance, optionally mark the image as not writeable to\n","            # pass by reference.\n","            image.flags.writeable = False\n","            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","            results = hands.process(image)\n","            results_p=pose.process(image)\n","\n","\n","            img=np.zeros_like(image,dtype=np.uint8)\n","\n","            mp_drawing.draw_landmarks(\n","            img,\n","            results_p.pose_landmarks,\n","            mp_pose.POSE_CONNECTIONS,\n","            landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style(),hands_or_pose='Pose')  \n","\n","            if results.multi_hand_landmarks:\n","              for hand_landmarks in results.multi_hand_landmarks:\n","                mp_drawing.draw_landmarks(\n","                    img,\n","                    hand_landmarks,\n","                    mp_hands.HAND_CONNECTIONS,\n","                    mp_drawing_styles.get_default_hand_landmarks_style(),\n","                    mp_drawing_styles.get_default_hand_connections_style(),\n","                    hands_or_pose='Hands')\n","\n","\n","            new_frame_time=time.time()\n","            fps = str(int(1/(new_frame_time-prev_frame_time)))\n","            prev_frame_time = new_frame_time\n","\n","            # Flip the image horizontally for a selfie-view display.\n","            if f==1:\n","              # image=cv2.flip(image,1)\n","              img=cv2.flip(img,1)\n","\n","            # save the mediapipe hand and pose video\n","            videoWriter.write(img)\n","\n","            # cv2.putText(image, fps, (7, 70), cv2.FONT_HERSHEY_SIMPLEX , 3, (100, 255, 0), 3, cv2.LINE_AA)\n","            # cv2.imshow('MediaPipe Hand and Pose', img)      \n","            # cv2.imshow('Original',cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n","            # if cv2.waitKey(5) & 0xFF == 27:\n","            #   break\n","      cap.release()\n","      videoWriter.release()\n","    cv2.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{},"source":["## Real Time Stick-Figure Generation From Webcam Input"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","import cv2\n","import mediapipe as mp\n","import numpy as np\n","import time\n","import os\n","\n","\n","mp_drawing = mp.solutions.drawing_utils\n","mp_drawing_styles = mp.solutions.drawing_styles\n","mp_pose = mp.solutions.pose\n","mp_hands = mp.solutions.hands\n","\n","\n","prev_frame_time = 0\n","new_frame_time = 0\n","\n","\n","# For webcam input:\n","cap = cv2.VideoCapture('n3.mp4')\n","# cap = cv2.VideoCapture(0)\n","fourcc = cv2.VideoWriter_fourcc('X', 'V', 'I', 'D')\n","\n","\n","videoWriter = cv2.VideoWriter('slomo1.avi', fourcc, 30.0, (224,224))\n","\n","with mp_pose.Pose(\n","        min_detection_confidence=0.5,\n","        min_tracking_confidence=0.5) as pose:\n","    with mp_hands.Hands(\n","        min_detection_confidence=0.5,\n","        min_tracking_confidence=0.5) as hands:\n","        while cap.isOpened():\n","            success, image = cap.read()\n","            if not success:\n","                print(\"Ignoring empty camera frame.\")\n","                break\n","                # If loading a video, use 'break' instead of 'continue'.\n","                # continue\n","\n","            image = cv2.resize(image, (224, 224), interpolation=cv2.INTER_AREA)\n","\n","            # To improve performance, optionally mark the image as not writeable to\n","            # pass by reference.\n","            image.flags.writeable = False\n","            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","            results = hands.process(image)\n","            results_p = pose.process(image)\n","\n","            img = np.zeros_like(image, dtype=np.uint8)\n","\n","            mp_drawing.draw_landmarks(\n","                img,\n","                results_p.pose_landmarks,\n","                mp_pose.POSE_CONNECTIONS,\n","                landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style(), hands_or_pose='Pose')\n","\n","            if results.multi_hand_landmarks:\n","                for hand_landmarks in results.multi_hand_landmarks:\n","                    mp_drawing.draw_landmarks(\n","                        img,\n","                        hand_landmarks,\n","                        mp_hands.HAND_CONNECTIONS,\n","                        mp_drawing_styles.get_default_hand_landmarks_style(),\n","                        mp_drawing_styles.get_default_hand_connections_style(),\n","                        hands_or_pose='Hands')\n","\n","            new_frame_time = time.time()\n","            fps = str(int(1/(new_frame_time-prev_frame_time)))\n","            prev_frame_time = new_frame_time\n","\n","            # Flip the image horizontally for a selfie-view display.\n","            image = cv2.flip(image, 1)\n","            img = cv2.flip(img, 1)\n","\n","            # save the mediapipe hand and pose video\n","            # videoWriter.write(img)\n","\n","            cv2.putText(image, fps, (7, 70), cv2.FONT_HERSHEY_SIMPLEX,\n","                        3, (100, 255, 0), 3, cv2.LINE_AA)\n","            cv2.imshow('MediaPipe Hand and Pose', img)\n","            cv2.imshow('Original', cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n","            if cv2.waitKey(5) & 0xFF == 27:\n","                break\n","cap.release()\n","videoWriter.release()\n","cv2.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{},"source":["## making the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from tokenizers import Tokenizer\n","from tokenizers.models import WordLevel\n","from tokenizers.trainers import WordLevelTrainer\n","from tokenizers.pre_tokenizers import Whitespace\n","from pathlib import Path"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ds={'ne':['म घर मा धेरै काम गर्छु ।','मेरो घर भक्तपुर मा छ ।','म संग धेरै पैसा छैन ।','मेरो धेरै साथी हरु छन् ।','मेरो साथी हरु भक्तपुर मा छन् ।','तिम्रो काम धेरै छ ।',\n","          'म लाई अण्डा मनपर्छ ।','तिम्रो काम हरु म लाई छैन ।','म संग अण्डा छैन ।','तिम्रो काम छैन पैसा छैन ।','म तिम्रो पैसा खान्छु ।','तिमी संग अण्डा छैन ।',\n","          'तिमी म लाई मनपर्छ ।','भक्तपुर मा धेरै काम छ ।','म अण्डा खान्छु ।','तिमी हरु मेरो साथी हो ।','म भक्तपुर मा काम गर्छु ।','म लाई भक्तपुर मनपर्छ ।',\n","          'म संग मेरो साथी छ ।','मेरो साथी लाई अण्डा मनपर्छ ।']}\n","ds"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_all_sentences(ds,lang):\n","    for item in ds[lang]:\n","        yield item\n","\n","\n","def get_or_build_tokenizer(filename, ds, lang):\n","    tokenizer_path = Path(filename.format(lang))\n","    if not Path.exists(tokenizer_path):\n","        # Most code taken from: https://huggingface.co/docs/tokenizers/quicktour\n","        tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n","        tokenizer.pre_tokenizer = Whitespace()\n","        trainer = WordLevelTrainer(\n","            special_tokens=[\"[UNK]\", \"[PAD]\", \"[SOS]\", \"[EOS]\"], min_frequency=1)\n","        tokenizer.train_from_iterator(\n","            get_all_sentences(ds, lang), trainer=trainer)\n","        tokenizer.save(str(tokenizer_path))\n","    else:\n","        tokenizer = Tokenizer.from_file(str(tokenizer_path))\n","\n","    return tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# making the tokenizer\n","\n","# tok=get_or_build_tokenizer('tokenizer_sign_lang_{0}.json',ds,'ne')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tok.get_vocab()"]}],"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":4}
