{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Media-Pipe Preprocessing"]},{"cell_type":"markdown","metadata":{},"source":["## Convert Multiple Raw Videos into Mediapipe Stick-Figures"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n","OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1723633160.329710    6930 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n","I0000 00:00:1723633160.333018    6990 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.2), renderer: Mesa Intel(R) UHD Graphics (ICL GT1)\n","INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n","I0000 00:00:1723633160.342759    6930 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n","I0000 00:00:1723633160.345027    7001 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.2), renderer: Mesa Intel(R) UHD Graphics (ICL GT1)\n","W0000 00:00:1723633160.369530    6991 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","W0000 00:00:1723633160.402133    6998 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","W0000 00:00:1723633160.475636    6974 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","/home/bikasherl/miniconda3/envs/bajra/lib/python3.12/site-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n","  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n","W0000 00:00:1723633160.511608    6974 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"]},{"name":"stdout","output_type":"stream","text":["Ignoring empty camera frame.\n"]},{"name":"stderr","output_type":"stream","text":["OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n","OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n","I0000 00:00:1723633171.866237    6930 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n","I0000 00:00:1723633171.867286    7031 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.2), renderer: Mesa Intel(R) UHD Graphics (ICL GT1)\n","I0000 00:00:1723633171.875009    6930 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n","I0000 00:00:1723633171.875914    7042 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.2), renderer: Mesa Intel(R) UHD Graphics (ICL GT1)\n","W0000 00:00:1723633171.892148    7036 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","W0000 00:00:1723633171.922045    7034 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","W0000 00:00:1723633171.985636    7024 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","W0000 00:00:1723633172.012047    7024 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"]},{"name":"stdout","output_type":"stream","text":["Ignoring empty camera frame.\n"]},{"name":"stderr","output_type":"stream","text":["OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n","OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n","I0000 00:00:1723633183.453017    6930 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n","I0000 00:00:1723633183.454342    7083 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.2), renderer: Mesa Intel(R) UHD Graphics (ICL GT1)\n","I0000 00:00:1723633183.464414    6930 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n","I0000 00:00:1723633183.465381    7094 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.2), renderer: Mesa Intel(R) UHD Graphics (ICL GT1)\n","W0000 00:00:1723633183.479984    7088 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","W0000 00:00:1723633183.508215    7090 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","W0000 00:00:1723633183.563633    7073 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","W0000 00:00:1723633183.593022    7079 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"]},{"name":"stdout","output_type":"stream","text":["Ignoring empty camera frame.\n"]},{"name":"stderr","output_type":"stream","text":["OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n","OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n","I0000 00:00:1723633193.479566    6930 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n","I0000 00:00:1723633193.480628    7134 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.2), renderer: Mesa Intel(R) UHD Graphics (ICL GT1)\n","I0000 00:00:1723633193.488270    6930 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n","I0000 00:00:1723633193.489398    7145 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.2), renderer: Mesa Intel(R) UHD Graphics (ICL GT1)\n","W0000 00:00:1723633193.514035    7139 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","W0000 00:00:1723633193.537031    7138 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","W0000 00:00:1723633193.586404    7131 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","W0000 00:00:1723633193.615426    7126 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"]},{"name":"stdout","output_type":"stream","text":["Ignoring empty camera frame.\n"]},{"name":"stderr","output_type":"stream","text":["OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n","OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n","I0000 00:00:1723633204.479012    6930 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n","I0000 00:00:1723633204.479992    7185 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.2), renderer: Mesa Intel(R) UHD Graphics (ICL GT1)\n","I0000 00:00:1723633204.491427    6930 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n","I0000 00:00:1723633204.492457    7196 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.2), renderer: Mesa Intel(R) UHD Graphics (ICL GT1)\n","W0000 00:00:1723633204.509286    7189 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","W0000 00:00:1723633204.528624    7192 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","W0000 00:00:1723633204.605346    7181 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","W0000 00:00:1723633204.624864    7177 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"]},{"name":"stdout","output_type":"stream","text":["Ignoring empty camera frame.\n"]},{"name":"stderr","output_type":"stream","text":["OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n","OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n","I0000 00:00:1723633217.334000    6930 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n","I0000 00:00:1723633217.335097    7238 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.2), renderer: Mesa Intel(R) UHD Graphics (ICL GT1)\n","I0000 00:00:1723633217.346603    6930 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n","I0000 00:00:1723633217.347632    7249 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.2), renderer: Mesa Intel(R) UHD Graphics (ICL GT1)\n","W0000 00:00:1723633217.364035    7242 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","W0000 00:00:1723633217.387107    7239 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","W0000 00:00:1723633217.438546    7228 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","W0000 00:00:1723633217.471253    7228 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"]},{"name":"stdout","output_type":"stream","text":["Ignoring empty camera frame.\n"]},{"name":"stderr","output_type":"stream","text":["OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n","OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n","I0000 00:00:1723633229.780174    6930 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n","I0000 00:00:1723633229.781253    7290 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.2), renderer: Mesa Intel(R) UHD Graphics (ICL GT1)\n","I0000 00:00:1723633229.789971    6930 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n","I0000 00:00:1723633229.791038    7301 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.2), renderer: Mesa Intel(R) UHD Graphics (ICL GT1)\n","W0000 00:00:1723633229.806368    7294 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","W0000 00:00:1723633229.833975    7294 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","W0000 00:00:1723633229.886375    7284 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","W0000 00:00:1723633229.906406    7287 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"]},{"name":"stdout","output_type":"stream","text":["Ignoring empty camera frame.\n"]},{"name":"stderr","output_type":"stream","text":["OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n","OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n","I0000 00:00:1723633242.992682    6930 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n","I0000 00:00:1723633242.994300    7342 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.2), renderer: Mesa Intel(R) UHD Graphics (ICL GT1)\n","I0000 00:00:1723633243.003170    6930 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n","I0000 00:00:1723633243.004123    7353 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.2), renderer: Mesa Intel(R) UHD Graphics (ICL GT1)\n","W0000 00:00:1723633243.019651    7349 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","W0000 00:00:1723633243.046071    7346 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","W0000 00:00:1723633243.110837    7333 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","W0000 00:00:1723633243.137302    7336 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"]},{"name":"stdout","output_type":"stream","text":["Ignoring empty camera frame.\n"]}],"source":["\n","import cv2\n","import mediapipe as mp\n","import numpy as np\n","import time\n","import os\n","import glob\n","\n","parent_directory='data'\n","video_dir='mero_dherei_sathi_haru_chhan/'\n","\n","\n","video_path=os.path.join(parent_directory,video_dir)\n","\n","\n","mp_drawing = mp.solutions.drawing_utils\n","mp_drawing_styles = mp.solutions.drawing_styles\n","mp_pose = mp.solutions.pose\n","mp_hands = mp.solutions.hands\n","\n","\n","prev_frame_time=0\n","new_frame_time=0\n","\n","# For webcam input:\n","# cap = cv2.VideoCapture(0)\n","\n","\n","for video in glob.glob(video_path+'*'):\n","\n","  cap=cv2.VideoCapture(video)\n","\n","  fourcc = cv2.VideoWriter_fourcc('X','V','I','D')\n","\n","  save_video_path=os.path.join('processed_data/'+video_dir+video.removeprefix(video_path))\n","  videoWriter = cv2.VideoWriter(save_video_path, fourcc, 30.0, (224,224))\n","\n","\n","  with mp_pose.Pose(\n","      min_detection_confidence=0.5,\n","      min_tracking_confidence=0.5) as pose:\n","    with mp_hands.Hands(\n","        min_detection_confidence=0.5,\n","        min_tracking_confidence=0.5) as hands:\n","      while cap.isOpened():\n","        success, image = cap.read()\n","        if not success:\n","          print(\"Ignoring empty camera frame.\")\n","          break\n","          # If loading a video, use 'break' instead of 'continue'.\n","          # continue\n","\n","        image=cv2.resize(image,(224,224),interpolation=cv2.INTER_AREA)\n","\n","        # To improve performance, optionally mark the image as not writeable to\n","        # pass by reference.\n","        image.flags.writeable = False\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        results = hands.process(image)\n","        results_p=pose.process(image)\n","\n","\n","        img=np.zeros_like(image,dtype=np.uint8)\n","\n","        mp_drawing.draw_landmarks(\n","        img,\n","        results_p.pose_landmarks,\n","        mp_pose.POSE_CONNECTIONS,\n","        landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style(),hands_or_pose='Pose')  \n","\n","        if results.multi_hand_landmarks:\n","          for hand_landmarks in results.multi_hand_landmarks:\n","            mp_drawing.draw_landmarks(\n","                img,\n","                hand_landmarks,\n","                mp_hands.HAND_CONNECTIONS,\n","                mp_drawing_styles.get_default_hand_landmarks_style(),\n","                mp_drawing_styles.get_default_hand_connections_style(),\n","                hands_or_pose='Hands')\n","\n","\n","        new_frame_time=time.time()\n","        fps = str(int(1/(new_frame_time-prev_frame_time)))\n","        prev_frame_time = new_frame_time\n","\n","        # Flip the image horizontally for a selfie-view display.\n","        image=cv2.flip(image,1)\n","        img=cv2.flip(img,1)\n","\n","        # save the mediapipe hand and pose video\n","        videoWriter.write(img)\n","\n","        cv2.putText(image, fps, (7, 70), cv2.FONT_HERSHEY_SIMPLEX , 3, (100, 255, 0), 3, cv2.LINE_AA)\n","        cv2.imshow('MediaPipe Hand and Pose', img)      \n","        cv2.imshow('Original',cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n","        if cv2.waitKey(5) & 0xFF == 27:\n","          break\n","  cap.release()\n","  videoWriter.release()\n","cv2.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{},"source":["## Real Time Stick-Figure Generation From Webcam Input"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["I0000 00:00:1723805563.886720    5920 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n","I0000 00:00:1723805563.887895    8000 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.2), renderer: Mesa Intel(R) UHD Graphics (ICL GT1)\n","I0000 00:00:1723805563.899278    5920 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n","I0000 00:00:1723805563.900711    8011 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.2), renderer: Mesa Intel(R) UHD Graphics (ICL GT1)\n","W0000 00:00:1723805563.917761    8002 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","W0000 00:00:1723805563.940920    8008 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","W0000 00:00:1723805563.992520    7991 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","W0000 00:00:1723805564.028766    7991 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"]}],"source":["\n","import cv2\n","import mediapipe as mp\n","import numpy as np\n","import time\n","import os\n","\n","\n","mp_drawing = mp.solutions.drawing_utils\n","mp_drawing_styles = mp.solutions.drawing_styles\n","mp_pose = mp.solutions.pose\n","mp_hands = mp.solutions.hands\n","\n","\n","prev_frame_time = 0\n","new_frame_time = 0\n","\n","\n","# For webcam input:\n","cap = cv2.VideoCapture('m_dherei_sathi_hc.mp4')\n","\n","fourcc = cv2.VideoWriter_fourcc('X', 'V', 'I', 'D')\n","\n","\n","videoWriter = cv2.VideoWriter('slomo1.avi', fourcc, 15.0, (224,224))\n","\n","with mp_pose.Pose(\n","        min_detection_confidence=0.5,\n","        min_tracking_confidence=0.5) as pose:\n","    with mp_hands.Hands(\n","        min_detection_confidence=0.5,\n","        min_tracking_confidence=0.5) as hands:\n","        while cap.isOpened():\n","            success, image = cap.read()\n","            if not success:\n","                print(\"Ignoring empty camera frame.\")\n","                break\n","                # If loading a video, use 'break' instead of 'continue'.\n","                # continue\n","\n","            image = cv2.resize(image, (224, 224), interpolation=cv2.INTER_AREA)\n","\n","            # To improve performance, optionally mark the image as not writeable to\n","            # pass by reference.\n","            image.flags.writeable = False\n","            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","            results = hands.process(image)\n","            results_p = pose.process(image)\n","\n","            img = np.zeros_like(image, dtype=np.uint8)\n","\n","            mp_drawing.draw_landmarks(\n","                img,\n","                results_p.pose_landmarks,\n","                mp_pose.POSE_CONNECTIONS,\n","                landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style(), hands_or_pose='Pose')\n","\n","            if results.multi_hand_landmarks:\n","                for hand_landmarks in results.multi_hand_landmarks:\n","                    mp_drawing.draw_landmarks(\n","                        img,\n","                        hand_landmarks,\n","                        mp_hands.HAND_CONNECTIONS,\n","                        mp_drawing_styles.get_default_hand_landmarks_style(),\n","                        mp_drawing_styles.get_default_hand_connections_style(),\n","                        hands_or_pose='Hands')\n","\n","            new_frame_time = time.time()\n","            fps = str(int(1/(new_frame_time-prev_frame_time)))\n","            prev_frame_time = new_frame_time\n","\n","            # Flip the image horizontally for a selfie-view display.\n","            image = cv2.flip(image, 1)\n","            img = cv2.flip(img, 1)\n","\n","            # save the mediapipe hand and pose video\n","            # videoWriter.write(image)\n","\n","            cv2.putText(image, fps, (7, 70), cv2.FONT_HERSHEY_SIMPLEX,\n","                        3, (100, 255, 0), 3, cv2.LINE_AA)\n","            cv2.imshow('MediaPipe Hand and Pose', img)\n","            cv2.imshow('Original', cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n","            if cv2.waitKey(5) & 0xFF == 27:\n","                break\n","cap.release()\n","videoWriter.release()\n","cv2.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{},"source":["## making the dataset"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["from tokenizers import Tokenizer\n","from tokenizers.models import WordLevel\n","from tokenizers.trainers import WordLevelTrainer\n","from tokenizers.pre_tokenizers import Whitespace\n","from pathlib import Path"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["म घर मा धेरै काम गर्छु । मेरो घर भक्तपुर मा छ । म संग धेरै पैसा छैन । मेरो धेरै साथी हरु छन् । मेरो साथी हरु भक्तपुर मा छन् ।"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/plain":["{'ne': ['म घर मा धेरै काम गर्छु ।',\n","  'मेरो घर भक्तपुर मा छ ।',\n","  'म संग धेरै पैसा छैन ।',\n","  'मेरो धेरै साथी हरु छन् ।',\n","  'मेरो साथी हरु भक्तपुर मा छन् ।']}"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["ds={'ne':['म घर मा धेरै काम गर्छु ।','मेरो घर भक्तपुर मा छ ।','म संग धेरै पैसा छैन ।','मेरो धेरै साथी हरु छन् ।','मेरो साथी हरु भक्तपुर मा छन् ।']}\n","ds"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def get_all_sentences(ds,lang):\n","    for item in ds[lang]:\n","        yield item\n","\n","\n","def get_or_build_tokenizer(filename, ds, lang):\n","    tokenizer_path = Path(filename.format(lang))\n","    if not Path.exists(tokenizer_path):\n","        # Most code taken from: https://huggingface.co/docs/tokenizers/quicktour\n","        tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n","        tokenizer.pre_tokenizer = Whitespace()\n","        trainer = WordLevelTrainer(\n","            special_tokens=[\"[UNK]\", \"[PAD]\", \"[SOS]\", \"[EOS]\"], min_frequency=1)\n","        tokenizer.train_from_iterator(\n","            get_all_sentences(ds, lang), trainer=trainer)\n","        tokenizer.save(str(tokenizer_path))\n","    else:\n","        tokenizer = Tokenizer.from_file(str(tokenizer_path))\n","\n","    return tokenizer"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["{'छैन': 17,\n"," '[SOS]': 2,\n"," '।': 4,\n"," 'छन्': 9,\n"," 'म': 11,\n"," 'संग': 19,\n"," 'साथी': 12,\n"," '[UNK]': 0,\n"," 'मेरो': 7,\n"," 'हरु': 13,\n"," '[PAD]': 1,\n"," '[EOS]': 3,\n"," 'काम': 14,\n"," 'गर्छु': 15,\n"," 'मा': 6,\n"," 'छ': 16,\n"," 'धेरै': 5,\n"," 'भक्तपुर': 10,\n"," 'पैसा': 18,\n"," 'घर': 8}"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["# making the tokenizer\n","\n","tok=get_or_build_tokenizer('tokenizer_sign_lang_{0}.json',ds,'ne')"]},{"cell_type":"markdown","metadata":{},"source":["## random clipping"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install -q pytorchvideo transformers evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pytorchvideo\n","\n","pytorchvideo.data.make_clip_sampler(\"random\", clip_duration)"]}],"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":4}
